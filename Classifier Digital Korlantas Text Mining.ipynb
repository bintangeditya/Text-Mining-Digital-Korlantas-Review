{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content_clean</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>terima kasih</td>\n",
       "      <td>Positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>panjang sim tp bkan nama yg daftar aplikasi</td>\n",
       "      <td>Positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nanya kalo sim udan mati th panjang</td>\n",
       "      <td>Positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>banding polres kacau</td>\n",
       "      <td>Negatif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mohon maaf gagal verif ktp yaa</td>\n",
       "      <td>Negatif</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 content_clean Sentiment\n",
       "0                                 terima kasih   Positif\n",
       "1  panjang sim tp bkan nama yg daftar aplikasi   Positif\n",
       "2          nanya kalo sim udan mati th panjang   Positif\n",
       "3                         banding polres kacau   Negatif\n",
       "4               mohon maaf gagal verif ktp yaa   Negatif"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load dataset\n",
    "def load_data():\n",
    "    data = pd.read_csv(\"Data/digital_korlantas_reviews_cleaned.csv\")\n",
    "    return data\n",
    "\n",
    "df = load_data()\n",
    "df = df[[\"content_clean\",\"Sentiment\"]]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "content_clean      string\n",
       "Sentiment        category\n",
       "dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.astype({\"content_clean\":\"string\",\"Sentiment\":\"category\"})\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<500x1218 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 4511 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf = TfidfVectorizer()\n",
    "text_tf=tf.fit_transform(df[\"content_clean\"].astype(\"U\"))\n",
    "text_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(text_tf,df[\"Sentiment\"], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc 0.67\n",
      "prec 0.67\n",
      "rec 0.67\n",
      "f1 0.67\n",
      "[[ 3  0 19]\n",
      " [ 0  0 14]\n",
      " [ 0  0 64]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Negatif       1.00      0.14      0.24        22\n",
      "      Netral       0.00      0.00      0.00        14\n",
      "     Positif       0.66      1.00      0.80        64\n",
      "\n",
      "    accuracy                           0.67       100\n",
      "   macro avg       0.55      0.38      0.35       100\n",
      "weighted avg       0.64      0.67      0.56       100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = MultinomialNB().fit(X_train,y_train)\n",
    "predicted = model.predict(X_test)\n",
    "print(\"acc\",accuracy_score(y_test,predicted))\n",
    "print(\"prec\",precision_score(y_test,predicted,average=\"micro\"))\n",
    "print(\"rec\",recall_score(y_test,predicted,average=\"micro\"))\n",
    "print(\"f1\",f1_score(y_test,predicted,average=\"micro\"))\n",
    "print(confusion_matrix(y_test,predicted))\n",
    "print(classification_report(y_test, predicted, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc 0.58\n",
      "prec 0.58\n",
      "rec 0.58\n",
      "f1 0.58\n",
      "[[ 0  0 14]\n",
      " [ 0  0  7]\n",
      " [ 0  0 29]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Negatif       0.00      0.00      0.00        14\n",
      "      Netral       0.00      0.00      0.00         7\n",
      "     Positif       0.58      1.00      0.73        29\n",
      "\n",
      "    accuracy                           0.58        50\n",
      "   macro avg       0.19      0.33      0.24        50\n",
      "weighted avg       0.34      0.58      0.43        50\n",
      "\n",
      "==================================================================\n",
      "acc 0.58\n",
      "prec 0.58\n",
      "rec 0.58\n",
      "f1 0.58\n",
      "[[ 1  0 13]\n",
      " [ 0  0  8]\n",
      " [ 0  0 28]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Negatif       1.00      0.07      0.13        14\n",
      "      Netral       0.00      0.00      0.00         8\n",
      "     Positif       0.57      1.00      0.73        28\n",
      "\n",
      "    accuracy                           0.58        50\n",
      "   macro avg       0.52      0.36      0.29        50\n",
      "weighted avg       0.60      0.58      0.44        50\n",
      "\n",
      "==================================================================\n",
      "acc 0.56\n",
      "prec 0.56\n",
      "rec 0.56\n",
      "f1 0.56\n",
      "[[ 0  0 15]\n",
      " [ 0  0  7]\n",
      " [ 0  0 28]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Negatif       0.00      0.00      0.00        15\n",
      "      Netral       0.00      0.00      0.00         7\n",
      "     Positif       0.56      1.00      0.72        28\n",
      "\n",
      "    accuracy                           0.56        50\n",
      "   macro avg       0.19      0.33      0.24        50\n",
      "weighted avg       0.31      0.56      0.40        50\n",
      "\n",
      "==================================================================\n",
      "acc 0.62\n",
      "prec 0.62\n",
      "rec 0.62\n",
      "f1 0.62\n",
      "[[ 1  0  9]\n",
      " [ 1  0  9]\n",
      " [ 0  0 30]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Negatif       0.50      0.10      0.17        10\n",
      "      Netral       0.00      0.00      0.00        10\n",
      "     Positif       0.62      1.00      0.77        30\n",
      "\n",
      "    accuracy                           0.62        50\n",
      "   macro avg       0.38      0.37      0.31        50\n",
      "weighted avg       0.47      0.62      0.49        50\n",
      "\n",
      "==================================================================\n",
      "acc 0.68\n",
      "prec 0.68\n",
      "rec 0.68\n",
      "f1 0.68\n",
      "[[ 0  0  6]\n",
      " [ 0  0 10]\n",
      " [ 0  0 34]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Negatif       0.00      0.00      0.00         6\n",
      "      Netral       0.00      0.00      0.00        10\n",
      "     Positif       0.68      1.00      0.81        34\n",
      "\n",
      "    accuracy                           0.68        50\n",
      "   macro avg       0.23      0.33      0.27        50\n",
      "weighted avg       0.46      0.68      0.55        50\n",
      "\n",
      "==================================================================\n",
      "acc 0.82\n",
      "prec 0.82\n",
      "rec 0.82\n",
      "f1 0.82\n",
      "[[ 1  0  5]\n",
      " [ 0  0  4]\n",
      " [ 0  0 40]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Negatif       1.00      0.17      0.29         6\n",
      "      Netral       0.00      0.00      0.00         4\n",
      "     Positif       0.82      1.00      0.90        40\n",
      "\n",
      "    accuracy                           0.82        50\n",
      "   macro avg       0.61      0.39      0.39        50\n",
      "weighted avg       0.77      0.82      0.75        50\n",
      "\n",
      "==================================================================\n",
      "acc 0.74\n",
      "prec 0.74\n",
      "rec 0.74\n",
      "f1 0.74\n",
      "[[ 2  0  9]\n",
      " [ 0  0  4]\n",
      " [ 0  0 35]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Negatif       1.00      0.18      0.31        11\n",
      "      Netral       0.00      0.00      0.00         4\n",
      "     Positif       0.73      1.00      0.84        35\n",
      "\n",
      "    accuracy                           0.74        50\n",
      "   macro avg       0.58      0.39      0.38        50\n",
      "weighted avg       0.73      0.74      0.66        50\n",
      "\n",
      "==================================================================\n",
      "acc 0.72\n",
      "prec 0.72\n",
      "rec 0.72\n",
      "f1 0.72\n",
      "[[ 0  0  7]\n",
      " [ 0  0  7]\n",
      " [ 0  0 36]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Negatif       0.00      0.00      0.00         7\n",
      "      Netral       0.00      0.00      0.00         7\n",
      "     Positif       0.72      1.00      0.84        36\n",
      "\n",
      "    accuracy                           0.72        50\n",
      "   macro avg       0.24      0.33      0.28        50\n",
      "weighted avg       0.52      0.72      0.60        50\n",
      "\n",
      "==================================================================\n",
      "acc 0.76\n",
      "prec 0.76\n",
      "rec 0.76\n",
      "f1 0.76\n",
      "[[ 3  0  4]\n",
      " [ 0  0  8]\n",
      " [ 0  0 35]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Negatif       1.00      0.43      0.60         7\n",
      "      Netral       0.00      0.00      0.00         8\n",
      "     Positif       0.74      1.00      0.85        35\n",
      "\n",
      "    accuracy                           0.76        50\n",
      "   macro avg       0.58      0.48      0.48        50\n",
      "weighted avg       0.66      0.76      0.68        50\n",
      "\n",
      "==================================================================\n",
      "acc 0.68\n",
      "prec 0.68\n",
      "rec 0.68\n",
      "f1 0.68\n",
      "[[ 2  0  9]\n",
      " [ 0  0  7]\n",
      " [ 0  0 32]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Negatif       1.00      0.18      0.31        11\n",
      "      Netral       0.00      0.00      0.00         7\n",
      "     Positif       0.67      1.00      0.80        32\n",
      "\n",
      "    accuracy                           0.68        50\n",
      "   macro avg       0.56      0.39      0.37        50\n",
      "weighted avg       0.65      0.68      0.58        50\n",
      "\n",
      "==================================================================\n",
      "Average========================================================\n",
      "acc : 0.6739999999999999\n",
      "prec : 0.6739999999999999\n",
      "rec : 0.6739999999999999\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=10)\n",
    "X_4kfold = text_tf.toarray()\n",
    "Y_4kfold  = df[\"Sentiment\"].copy()\n",
    "def cross_val(estimator):\n",
    "    acc = []\n",
    "    prec = []\n",
    "    rec = []\n",
    "    for train_index, test_index in kf.split(X_4kfold,Y_4kfold):\n",
    "        X_train, X_test = X_4kfold[train_index], X_4kfold[test_index]\n",
    "        y_train, y_test = Y_4kfold[train_index], Y_4kfold[test_index]\n",
    "        model = estimator.fit(X_train,y_train)\n",
    "        predicted = model.predict(X_test)\n",
    "        acc.append(accuracy_score(y_test,predicted))\n",
    "        prec.append(precision_score(y_test,predicted,average=\"micro\"))\n",
    "        rec.append(recall_score(y_test,predicted,average=\"micro\"))\n",
    "        \n",
    "        print(\"acc\",accuracy_score(y_test,predicted))\n",
    "        print(\"prec\",precision_score(y_test,predicted,average=\"micro\"))\n",
    "        print(\"rec\",recall_score(y_test,predicted,average=\"micro\"))\n",
    "        print(\"f1\",f1_score(y_test,predicted,average=\"micro\"))\n",
    "        print(confusion_matrix(y_test,predicted))\n",
    "        print(classification_report(y_test, predicted, zero_division=0))\n",
    "        print(\"==================================================================\")\n",
    "    \n",
    "    print(\"Average========================================================\")\n",
    "    print(f\"acc : {np.mean(acc)}\")\n",
    "    print(f\"prec : {np.mean(prec)}\")\n",
    "    print(f\"rec : {np.mean(rec)}\")\n",
    "\n",
    "model = MultinomialNB()\n",
    "cross_val(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
