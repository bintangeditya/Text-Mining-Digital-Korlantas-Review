{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "from sklearn.naive_bayes import MultinomialNB\r\n",
    "from sklearn.feature_extraction.text import CountVectorizer\r\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\r\n",
    "# from sklearn.feature_extraction.text import TfidfTransformer\r\n",
    "from sklearn.pipeline import Pipeline\r\n",
    "from sklearn.model_selection import KFold, train_test_split\r\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score\r\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "# Load dataset\r\n",
    "def load_data():\r\n",
    "    data = pd.read_csv(\"digital_korlantas_reviews_5000_p.csv\")\r\n",
    "    return data\r\n",
    "\r\n",
    "df = load_data()\r\n",
    "df = df[[\"content_clean\",\"sentiment\"]]\r\n",
    "df.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                       content_clean sentiment\n",
       "0                                             mantap   Positif\n",
       "1                                               moga   Positif\n",
       "2                                                 ok   Positif\n",
       "3                              bantu buat sim online   Positif\n",
       "4  alhamdulillah sim darat selamat sampe rumah te...   Positif"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content_clean</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mantap</td>\n",
       "      <td>Positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>moga</td>\n",
       "      <td>Positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ok</td>\n",
       "      <td>Positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bantu buat sim online</td>\n",
       "      <td>Positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>alhamdulillah sim darat selamat sampe rumah te...</td>\n",
       "      <td>Positif</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "df = df.astype({\"content_clean\":\"string\",\"sentiment\":\"category\"})\r\n",
    "df.dtypes"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "content_clean      string\n",
       "sentiment        category\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "tf = TfidfVectorizer()\r\n",
    "text_tf=tf.fit_transform(df[\"content_clean\"].astype(\"U\"))\r\n",
    "text_tf"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<2632x3436 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 25143 stored elements in Compressed Sparse Row format>"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(text_tf,df[\"sentiment\"], test_size=0.2, random_state=42)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "print(f\"Positif class at train dataset {sum(y_train=='Positif')}\")\r\n",
    "print(f\"Positif class at train dataset {sum(y_train=='Negatif')}\")\r\n",
    "print(f\"Positif class at test dataset {sum(y_test=='Positif')}\")\r\n",
    "print(f\"Positif class at test dataset {sum(y_test=='Negatif')}\")\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Positif class at train dataset 1038\n",
      "Positif class at train dataset 1067\n",
      "Positif class at test dataset 270\n",
      "Positif class at test dataset 257\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "model = MultinomialNB().fit(X_train,y_train)\r\n",
    "predicted = model.predict(X_test)\r\n",
    "print(\"acc\",accuracy_score(y_test,predicted))\r\n",
    "print(\"prec\",precision_score(y_test,predicted,average=\"binary\", pos_label=\"Negatif\"))\r\n",
    "print(\"rec\",recall_score(y_test,predicted,average=\"binary\", pos_label=\"Negatif\"))\r\n",
    "print(\"f1\",f1_score(y_test,predicted,average=\"binary\", pos_label=\"Negatif\"))\r\n",
    "print(confusion_matrix(y_test,predicted))\r\n",
    "print(classification_report(y_test, predicted, zero_division=0))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "acc 0.793168880455408\n",
      "prec 0.7681159420289855\n",
      "rec 0.8249027237354085\n",
      "f1 0.7954971857410882\n",
      "[[212  45]\n",
      " [ 64 206]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Negatif       0.77      0.82      0.80       257\n",
      "     Positif       0.82      0.76      0.79       270\n",
      "\n",
      "    accuracy                           0.79       527\n",
      "   macro avg       0.79      0.79      0.79       527\n",
      "weighted avg       0.80      0.79      0.79       527\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "kf = KFold(n_splits=10)\r\n",
    "X_4kfold = text_tf.toarray()\r\n",
    "Y_4kfold  = df[\"sentiment\"].copy()\r\n",
    "def cross_val(estimator):\r\n",
    "    acc = []\r\n",
    "    prec = []\r\n",
    "    rec = []\r\n",
    "    f1 = []\r\n",
    "    for train_index, test_index in kf.split(X_4kfold,Y_4kfold):\r\n",
    "        X_train, X_test = X_4kfold[train_index], X_4kfold[test_index]\r\n",
    "        y_train, y_test = Y_4kfold[train_index], Y_4kfold[test_index]\r\n",
    "        model = estimator.fit(X_train,y_train)\r\n",
    "        predicted = model.predict(X_test)\r\n",
    "        acc.append(accuracy_score(y_test,predicted))\r\n",
    "        prec.append(precision_score(y_test,predicted,average=\"binary\", pos_label=\"Negatif\"))\r\n",
    "        rec.append(recall_score(y_test,predicted,average=\"binary\", pos_label=\"Negatif\"))\r\n",
    "        f1.append(f1_score(y_test,predicted,average=\"binary\", pos_label=\"Negatif\"))\r\n",
    "        \r\n",
    "        print(\"acc\",accuracy_score(y_test,predicted))\r\n",
    "        print(\"prec\",precision_score(y_test,predicted,average=\"binary\", pos_label=\"Negatif\"))\r\n",
    "        print(\"rec\",recall_score(y_test,predicted,average=\"binary\", pos_label=\"Negatif\"))\r\n",
    "        print(\"f1\",f1_score(y_test,predicted,average=\"binary\", pos_label=\"Negatif\"))\r\n",
    "        print(confusion_matrix(y_test,predicted))\r\n",
    "        print(classification_report(y_test, predicted, zero_division=0))\r\n",
    "        print(\"==================================================================\")\r\n",
    "    \r\n",
    "    print(\"Average========================================================\")\r\n",
    "    print(f\"acc : {np.mean(acc)}\")\r\n",
    "    print(f\"prec : {np.mean(prec)}\")\r\n",
    "    print(f\"rec : {np.mean(rec)}\")\r\n",
    "    print(f\"f1 : {np.mean(f1)}\")\r\n",
    "\r\n",
    "model = MultinomialNB()\r\n",
    "cross_val(model)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\binta\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\binta\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\binta\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "acc 0.678030303030303\n",
      "prec 0.0\n",
      "rec 0.0\n",
      "f1 0.0\n",
      "[[  0   0]\n",
      " [ 85 179]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Negatif       0.00      0.00      0.00         0\n",
      "     Positif       1.00      0.68      0.81       264\n",
      "\n",
      "    accuracy                           0.68       264\n",
      "   macro avg       0.50      0.34      0.40       264\n",
      "weighted avg       1.00      0.68      0.81       264\n",
      "\n",
      "==================================================================\n",
      "acc 0.6553030303030303\n",
      "prec 0.0\n",
      "rec 0.0\n",
      "f1 0.0\n",
      "[[  0   0]\n",
      " [ 91 173]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Negatif       0.00      0.00      0.00         0\n",
      "     Positif       1.00      0.66      0.79       264\n",
      "\n",
      "    accuracy                           0.66       264\n",
      "   macro avg       0.50      0.33      0.40       264\n",
      "weighted avg       1.00      0.66      0.79       264\n",
      "\n",
      "==================================================================\n",
      "acc 0.6273764258555133\n",
      "prec 0.0\n",
      "rec 0.0\n",
      "f1 0.0\n",
      "[[  0   0]\n",
      " [ 98 165]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Negatif       0.00      0.00      0.00         0\n",
      "     Positif       1.00      0.63      0.77       263\n",
      "\n",
      "    accuracy                           0.63       263\n",
      "   macro avg       0.50      0.31      0.39       263\n",
      "weighted avg       1.00      0.63      0.77       263\n",
      "\n",
      "==================================================================\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\binta\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "acc 0.596958174904943\n",
      "prec 0.0\n",
      "rec 0.0\n",
      "f1 0.0\n",
      "[[  0   0]\n",
      " [106 157]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Negatif       0.00      0.00      0.00         0\n",
      "     Positif       1.00      0.60      0.75       263\n",
      "\n",
      "    accuracy                           0.60       263\n",
      "   macro avg       0.50      0.30      0.37       263\n",
      "weighted avg       1.00      0.60      0.75       263\n",
      "\n",
      "==================================================================\n",
      "acc 0.8288973384030418\n",
      "prec 0.14\n",
      "rec 0.7777777777777778\n",
      "f1 0.23728813559322035\n",
      "[[  7   2]\n",
      " [ 43 211]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Negatif       0.14      0.78      0.24         9\n",
      "     Positif       0.99      0.83      0.90       254\n",
      "\n",
      "    accuracy                           0.83       263\n",
      "   macro avg       0.57      0.80      0.57       263\n",
      "weighted avg       0.96      0.83      0.88       263\n",
      "\n",
      "==================================================================\n",
      "acc 0.7224334600760456\n",
      "prec 1.0\n",
      "rec 0.7224334600760456\n",
      "f1 0.8388520971302428\n",
      "[[190  73]\n",
      " [  0   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Negatif       1.00      0.72      0.84       263\n",
      "     Positif       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.72       263\n",
      "   macro avg       0.50      0.36      0.42       263\n",
      "weighted avg       1.00      0.72      0.84       263\n",
      "\n",
      "==================================================================\n",
      "acc 0.779467680608365\n",
      "prec 1.0\n",
      "rec 0.779467680608365\n",
      "f1 0.8760683760683761\n",
      "[[205  58]\n",
      " [  0   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Negatif       1.00      0.78      0.88       263\n",
      "     Positif       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.78       263\n",
      "   macro avg       0.50      0.39      0.44       263\n",
      "weighted avg       1.00      0.78      0.88       263\n",
      "\n",
      "==================================================================\n",
      "acc 0.7452471482889734\n",
      "prec 1.0\n",
      "rec 0.7452471482889734\n",
      "f1 0.8540305010893245\n",
      "[[196  67]\n",
      " [  0   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Negatif       1.00      0.75      0.85       263\n",
      "     Positif       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.75       263\n",
      "   macro avg       0.50      0.37      0.43       263\n",
      "weighted avg       1.00      0.75      0.85       263\n",
      "\n",
      "==================================================================\n",
      "acc 0.7946768060836502\n",
      "prec 1.0\n",
      "rec 0.7946768060836502\n",
      "f1 0.885593220338983\n",
      "[[209  54]\n",
      " [  0   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Negatif       1.00      0.79      0.89       263\n",
      "     Positif       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.79       263\n",
      "   macro avg       0.50      0.40      0.44       263\n",
      "weighted avg       1.00      0.79      0.89       263\n",
      "\n",
      "==================================================================\n",
      "acc 0.7642585551330798\n",
      "prec 1.0\n",
      "rec 0.7642585551330798\n",
      "f1 0.8663793103448276\n",
      "[[201  62]\n",
      " [  0   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Negatif       1.00      0.76      0.87       263\n",
      "     Positif       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.76       263\n",
      "   macro avg       0.50      0.38      0.43       263\n",
      "weighted avg       1.00      0.76      0.87       263\n",
      "\n",
      "==================================================================\n",
      "Average========================================================\n",
      "acc : 0.7192648922686946\n",
      "prec : 0.514\n",
      "rec : 0.4583861427967892\n",
      "f1 : 0.4558211640564974\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}